# Sign-To-Speech_conversion
Unable to communicate verbally is a disability. So in order to communicate there are may ways ,one of the most popular method is use of predefined sign languages . The purpose of this project is to contribute recognizing American sign languages(ASL) to the field of automatic sign language recognition with maximum efficiency.This model basically focuses on the recognition of ASL,  the real time static gestures  are collected from Laptop Webcam. The most challenging part in the design of an automatic sign language translator is the design of a good classifier that can classify the input static gestures with high accuracy. CNN architecture is used to  design of classifier for sign languages recognition, in the proposed system . The system trained CNNs  for the classification of twenty five(5) alphabets using 150-200 images. The system has trained the classifier with different parameter configurations and tabulated the results. Compared to previous literature the proposed work attained an efficiency of 99.35% for our classifier .The result shows that accuracy improves as we include more data from different subjects during training.
